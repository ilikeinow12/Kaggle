{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom glob import glob\nimport os, random, time, gc, warnings\n\nfrom tqdm import tqdm_notebook\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom pdpbox import pdp, info_plots\n\nwarnings.filterwarnings('ignore')\n\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 500)\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data Laod ","metadata":{}},{"cell_type":"code","source":"#주최 측이 제공한 데이터셋 확인 \nglob('../input/titanic/*.*')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Load \ndef load_dataset(path) : \n    train = pd.read_csv(path + 'train.csv')\n    test = pd.read_csv(path + 'test.csv')\n    sample_submission = pd.read_csv(path + 'gender_submission.csv')\n    return train, test, sample_submission\n\npath = '../input/titanic/'\n%time train, test, sample_submission = load_dataset(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Explore","metadata":{}},{"cell_type":"code","source":"#test set = no 'Survived'(=target col)\n#train/test split by 'PassengerId' \ndisplay(train.head(3))\ndisplay(test.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('-- Size --')\nprint(f'Train-set : {train.shape}')\nprint(f'Test-set : {test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#columns only in Train-set\ntrain.columns.difference(test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.Understanding How Train/ Test split ","metadata":{}},{"cell_type":"code","source":"print('Mins/Max of PassengerId in Train-Set')\ndisplay(train.PassengerId.agg(['min', 'max']))\nprint('='*80)\nprint(len(train))\nprint()\nprint('Mins/Max of PassengerId in Test-Set')\ndisplay(test.PassengerId.agg(['min', 'max']))\nprint('='*80)\nprint(len(test))\n\n#PassengerId ? .. No meaning. So should be removed when modeling ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#distribution of features in each set \ntrain.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Compare Train vs. Test","metadata":{}},{"cell_type":"code","source":"#Pclass : almost same proportion \ntrain['Pclass'].value_counts().sort_index().plot(kind='bar', color='lightblue', label='train')\ntest['Pclass'].value_counts().sort_index().plot(kind='bar', color='lightcoral', label='test')\n\nplt.legend()\nplt.xlabel('Pclass')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of Pclass in Train/Test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Sex'].value_counts().sort_index().plot(kind='bar', color='lightblue', label='train')\ntest['Sex'].value_counts().sort_index().plot(kind='bar', color='lightcoral', label='test')\n\nplt.legend()\nplt.xlabel('Sex')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of Sex in Train/Test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Age : similar distribution \ntrain['Age'].plot(kind='hist', color='lightblue', label='train')\ntest['Age'].plot(kind='hist', color='lightcoral', alpha=0.3, label='test')\n\nplt.legend()\nplt.xlabel('Age')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of Age in Train/Test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sibsp : similar distribution \ntrain['SibSp'].plot(kind='hist', color='lightblue', label='train')\ntest['SibSp'].plot(kind='hist', color='lightcoral', alpha=0.3, label='test')\n\nplt.legend()\nplt.xlabel('SibSp')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of SibSp in Train/Test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Parch : similar distribution \ntrain['Parch'].plot(kind='hist', color='lightblue', label='train')\ntest['Parch'].plot(kind='hist', color='lightcoral', alpha = 0.3, label='test')\n\nplt.legend()\nplt.xlabel('Parch')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of Parch in Train/Test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train['Parch'].value_counts()/len(train['Parch']))\ndisplay(test['Parch'].value_counts()/len(test['Parch']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Embarked : almost same proportion \ntrain['Embarked'].value_counts().sort_index().plot(kind='bar', color='lightblue', label='train')\ntest['Embarked'].value_counts().sort_index().plot(kind='bar', color='lightcoral', alpha=0.3, label='test')\n\nplt.legend()\nplt.xlabel('Embarked')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of Embarked in Train/Test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fare : similar distribution \ntrain['Fare'].plot(kind='hist', color='lightblue', label='train')\ntest['Fare'].plot(kind='hist', color='lightcoral', alpha=0.3, label='test')\n\nplt.legend()\nplt.xlabel('Fare')\nplt.ylabel('num of Passengers')\nplt.title('Distribution of Fare in Train/Test set')\n\nplt.show()\n\n#Fare= 0인 경우가 존재.... 어떤 경우인지 확인 필요함 \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cabin .. Cabin has too many values so let it be explored later. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Missing Values  \n- Age, Cabin ","metadata":{}},{"cell_type":"code","source":"msno.matrix(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train Set')\ndisplay(train.isnull().sum())\nprint('='*80)\nprint('Test Set')\ndisplay(test.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.1. Dealing with missing values in 'Age'\n* Age 결측치를 가진 탑승자 정보 확인\n* 비슷한 정보를 가진 사람들의 평균 나이 확인하여 결측치 채우기","metadata":{}},{"cell_type":"code","source":"df_all=pd.concat([train, test])\n\npd.set_option('display.max_rows', 50)\ndf_all.Age.fillna(0, inplace=True)\nprint('Train/Test set - values in [Age]')\ndf_all.Age.value_counts()\n\n# total 263 missing values ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataframe with Missing values of Age \ndf_miss_age=df_all[df_all['Age']==0]\n\nfig=plt.figure(figsize=(10,5))\n\nax1=fig.add_subplot(1,3,1)\nax2=fig.add_subplot(1,3,2)\nax3=fig.add_subplot(1,3,3)\nplt.subplots_adjust(left=0.125, bottom=0.1,  right=1.5, top=0.9, wspace=0.2, hspace=0.35)\n\nsns.countplot(x='Pclass', palette='Set2', data=df_miss_age, ax=ax1)\nsns.countplot(x='Sex', palette='Set2', data=df_miss_age, ax=ax2, hue='Pclass')\nsns.countplot(x='SibSp', palette='Set2', data=df_miss_age, ax=ax3, hue='Pclass')\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(10,5))\nax1=fig.add_subplot(1,2,1)\nax2=fig.add_subplot(1,2,2)\nplt.subplots_adjust(left=0.125, bottom=0.1,  right=1.5, top=0.9, wspace=0.2, hspace=0.35)\n\nsns.countplot(x='Parch', palette='Set2', data=df_miss_age, ax=ax1, hue='Pclass')\nsns.countplot(x='Embarked', palette='Set2', data=df_miss_age, ax=ax2, hue='Pclass')\n\nplt.show()\n\n# 나이가 기재되지 않은 승객들은 Pclass에서 두드러진 차이를 보이고 있으므로 나이는 Pclass(+성별?)의 평균? 중앙값?으로 채워주기로 한다. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_all.groupby(['Sex','Pclass'])['Age'].agg('mean'))\nprint('='*80)\ndisplay(df_all.groupby(['Sex','Pclass'])['Age'].agg('median'))\n\n#평균과 중앙값이 크게 차이나지 않기에 그냥 중앙값으로 채워주기로 한다.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['Age'] = df_all['Age'].replace(0, np.nan)\ndf_all['Age']=df_all['Age'].fillna(df_all.groupby(['Sex', 'Pclass'])['Age'].transform('median'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train vs. test \ndf_all_train = df_all[df_all.PassengerId <=891]\ndf_all_test = df_all[df_all.PassengerId>891].drop('Survived', 1)\n\ndf_all_train['Age'].plot(kind='hist', color='lightblue', label='train')\ndf_all_test['Age'].plot(kind='hist', color='lightcoral', alpha=0.3, label='test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2 Dealing with missing values in 'Cabin'","metadata":{}},{"cell_type":"code","source":"miss = df_all.Cabin[df_all['Pclass']==1].isnull().sum(axis=0)\nnotmiss=df_all.Cabin[df_all['Pclass']==1].notnull().sum(axis=0)\nprint(f'Pclass=1 .. missing values : {miss},  existing values : {notmiss}')\nprint('='*80)\n\nmiss = df_all.Cabin[df_all['Pclass']==2].isnull().sum(axis=0)\nnotmiss=df_all.Cabin[df_all['Pclass']==2].notnull().sum(axis=0)\nprint(f'Pclass=2 .. missing values : {miss},  existing values : {notmiss}')\nprint('='*80)\n\nmiss = df_all.Cabin[df_all['Pclass']==3].isnull().sum(axis=0)\nnotmiss=df_all.Cabin[df_all['Pclass']==3].notnull().sum(axis=0)\nprint(f'Pclass=3 .. missing values : {miss},  existing values : {notmiss}')\n\n#주로 Pclass=1에서 Cabin values가 존재하는 것으로 보아, Cabin은 Pclass=1의 생존율 예측에 유의미한 영향을 미칠것이라 추론됨  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['Cabin'].fillna('X', inplace=True)\ndf_all['Ca']=df_all['Cabin'].str[:1]\n# Cabin의 알파벳과 숫자를 분리해서 알파벳+n번대로 만들어주고 이를 따로 분리  알파벳 -> [Ca]\n# NaN값은 임의의 알파펫 X값으로 분리해줌 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compare train vs. test \ndf_all_train = df_all[df_all.PassengerId <=891]\ndf_all_test = df_all[df_all.PassengerId>891].drop('Survived', 1)\n\nfig=plt.figure(figsize=(10,5))\nsns.countplot(x=df_all_train['Ca'], color='lightblue', label='train')\nsns.countplot(x=df_all_test['Ca'], color='lightcoral', alpha=0.3, label='test')\nplt.show();\n\n#F, G를 거의 학습하지 못할 것 같아서 확인을 해봐야겠다. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all[(df_all['Ca']=='F') | (df_all['Ca']=='G')]\n#G.. Cabin number가 G6로 같다. 따라서 괜찮을것같음. \n#F .. F를 보아하니.. Cabin num의 알파벳 뿐만 아니라 숫자도 중요할 것 같다.. 같은 객실=같은 가족인지 여부가 중요할 것 같음. \n# 같은 객실에 묵었는지 여부는 Cabin 말고도 Ticket으로 볼 수도 있다. \n# 티켓을 labeling 해볼까.. 싶기도 함. 그건 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all[df_all['Ca']=='X']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nsns.countplot(x=df_all['Ca'], palette='Set2', hue=df_all['Pclass'])\nplt.show()\n\n\n# A,B,C,T : pclass=1인 사람들만\n# F : Pclass=3\n# D : pclass=2\n# E,G : Pclass 2, 3\n# X : pclass=1,2,3\n\n# 위의 알파벳은 숫자 편차가 심하므로 Ca을 다시 5개의 카테코리(1,2,3,4,5)로 분류하자. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ca in tqdm_notebook(df_all['Ca']) : \n    if ca=='A' or ca=='B' or ca=='C' or ca=='T' :\n        df_all['Ca'].replace(ca, 1, inplace=True)\n    elif ca=='E' or ca=='G' :\n        df_all['Ca'].replace(ca, 2, inplace=True)\n    elif ca=='D' :\n        df_all['Ca'].replace(ca, 3, inplace=True) \n    elif ca=='F' :\n        df_all['Ca'].replace(ca, 4, inplace=True)\n    elif ca=='X' :\n        df_all['Ca'].replace(ca, 5, inplace=True)\n        \n#문자형 타입으로 \ndf_all.Ca.astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 filling the missing values - Embarked\nThere are two missing values on Embared, and referring to the notebook(\"https://www.kaggle.com/gunesevitan/titanic-advanced-feature-engineering-tutorial), fill the values with 'S'","metadata":{}},{"cell_type":"code","source":"df_all['Embarked']=df_all['Embarked'].fillna('S')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.4 missing value - Fare","metadata":{}},{"cell_type":"code","source":"df_all[df_all['Fare'].isnull()]\n# though there is one null in 'Fare', I don't think Fare is importand predictor.\n# So I would just drop the column Fare later. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6 Testing Baseline Models","metadata":{}},{"cell_type":"code","source":"#Baseline models를 평가하기 위해 train, test데이터 분류. \ndf_all_train = df_all[df_all.PassengerId <=891]\ndf_all_test = df_all[df_all.PassengerId>891].drop('Survived', 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#null 값 없음. \ndisplay(df_all_train.info())\nprint('='*80)\ndisplay(df_all_test.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implement Label Encoding \ncat_cols = ['Sex','Embarked', 'Ticket']  #원래 티켓은 드롭했는데 같은 캐빈에 머문 것을 확인할 수 있는 증거이므로 한번 레이블을 시도해보자. \n\nlbl = LabelEncoder()\nfor col in tqdm_notebook( cat_cols ):   \n    temp_df=pd.concat([df_all_train, df_all_test])\n    \n    lbl.fit( temp_df[col] )\n    df_all_train[col]=lbl.transform(df_all_train[col])\n    df_all_test[col]=lbl.transform(df_all_test[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_cols=['PassengerId', 'Survived', 'Name', 'Cabin', 'Fare']\ntarget_cols='Survived'\n\nX=df_all_train.drop(drop_cols,1)\ny=df_all_train[target_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(X.head())\ndisplay(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1st : RandomForest\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n\n\nval_scores=list()\n\nfor i , (trn_idx, val_idx) in tqdm_notebook(enumerate(cv.split(X, y))):\n    trn_data, trn_label = X.values[trn_idx, :], y[trn_idx]\n    val_data, val_label = X.values[val_idx, :], y[val_idx]\n\n    rf_model=RandomForestClassifier(\n        n_estimators=1000,\n        random_state=11,\n        class_weight='balanced').fit(trn_data,trn_label)\n\n    trn_acc = rf_model.score(trn_data, trn_label)\n    val_acc = rf_model.score(val_data, val_label)\n    \n    print(f'{i} Fold, train Accuracy : {trn_acc},  validation Accuracy ; {val_acc} ')\n          \n    val_scores.append(val_acc)\n\n          \nprint(f'Cross Validation Score : {np.mean(val_scores)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3rd : xgboost\n\nval_scores=list()\n\nfor i , (trn_idx, val_idx) in tqdm_notebook(enumerate(cv.split(X, y))):\n    trn_data, trn_label = X.values[trn_idx, :], y[trn_idx]\n    val_data, val_label = X.values[val_idx, :], y[val_idx]\n\n    xgb_model=xgb.XGBClassifier(\n        n_estimators=1000,\n        subsample=0.3,\n        reg_alpha=10,\n        random_state=11).fit(trn_data,trn_label)\n\n    trn_acc = xgb_model.score(trn_data, trn_label)\n    val_acc = xgb_model.score(val_data, val_label)\n    \n    print(f'{i} Fold, train Accuracy : {trn_acc},  validation Accuracy ; {val_acc} ')\n          \n    val_scores.append(val_acc)\n\n\nprint(f'Cross Validation Score : {np.mean(val_scores)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Feature Engineering - think of more features. \n- Fam_size  = Sib + Parch \n- Title  \n- Sib and Parch : I think them important features since whether one was with parents(it means one=childs) and whether one was elder or younger did affect the survival rates","metadata":{}},{"cell_type":"code","source":"#Referring to many notebooks of others, create Fam_size and Title columns. \n\ndf_all['Fam_size']=df_all['SibSp']+df_all['Parch']  #except oneself.  \ndf_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_train = df_all[df_all.PassengerId <=891]\ndf_all_test = df_all[df_all.PassengerId>891].drop('Survived', 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_train['Title'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_test['Title'].value_counts()\n\n#needs to narrow down  - Mr, Mrs, Miss\n# Master, Major, Rev, Col, Dr, Jonkheer, Sir, Don, Capt -> Mr \n# Dona, Mme -> Mrs \n# Mlle, Ms, Lady -> Miss ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for title in tqdm_notebook(df_all['Title']): \n    if title =='Master' or title =='Major' or title =='Rev' or title =='Col' or title =='Dr' or title =='Jonkheer' or title =='Sir' or \\\n    title =='Don' or title =='Capt' :\n        df_all['Title'].replace(title, 'Mr', inplace=True)\n    elif title =='Dona' or title =='Mme' or title=='the Countess' : \n        df_all['Title'].replace(title, 'Mrs', inplace=True)\n    elif title =='Mlle' or title =='Ms' or title =='Lady': \n        df_all['Title'].replace(title, 'Miss', inplace=True)\n        \ndf_all['Title'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.Testing Models with XGBoost ","metadata":{}},{"cell_type":"code","source":"#Baseline models를 평가하기 위해 train, test데이터 분류. \ndf_all_train = df_all[df_all.PassengerId <=891]\ndf_all_test = df_all[df_all.PassengerId>891].drop('Survived', 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_train.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implement Label Encoding \ncat_cols = ['Sex','Embarked', 'Title']  \n\nlbl = LabelEncoder()\nfor col in tqdm_notebook( cat_cols ):   \n    temp_df=pd.concat([df_all_train, df_all_test])\n    \n    lbl.fit( temp_df[col] )\n    df_all_train[col]=lbl.transform(df_all_train[col])\n    df_all_test[col]=lbl.transform(df_all_test[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train\ndrop_cols=['PassengerId','Ticket', 'Survived', 'Name', 'Cabin', 'Fare']\ntarget_cols='Survived'\n\nX=df_all_train.drop(drop_cols,1)\ny=df_all_train[target_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(X.head(3))\ndisplay(y.astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3rd : xgboost\nval_scores=list()  \n\nfor i , (trn_idx, val_idx) in tqdm_notebook(enumerate(cv.split(X, y))):\n    trn_data, trn_label = X.values[trn_idx, :], y[trn_idx]\n    val_data, val_label = X.values[val_idx, :], y[val_idx]\n\n    xgb_model=xgb.XGBClassifier(\n              n_estimators=1000,\n        subsample=0.3,\n        reg_alpha=10, \n        random_state=11).fit(trn_data,trn_label)\n\n    trn_acc = xgb_model.score(trn_data, trn_label)\n    val_acc = xgb_model.score(val_data, val_label)\n    \n    print(f'{i} Fold, train Accuracy : {trn_acc},  validation Accuracy ; {val_acc} ')\n          \n    val_scores.append(val_acc)\n    \n\nprint(f'Cross Validation Score : {np.mean(val_scores)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. test data import, preprocessing","metadata":{}},{"cell_type":"code","source":"# df_test = pd.read_csv(\"../input/titanic/test.csv\")\n# df_test.set_index('PassengerId', inplace=True)\n# msno.matrix(df_test)\ndf_all_test.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train\ndrop_cols=['PassengerId','Ticket', 'Name', 'Cabin', 'Fare']\n\nX_test=df_all_test.drop(drop_cols,1)\nX_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(X.columns)\ndisplay(X_test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = xgb_model.predict(X_test.values).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId':df_all_test.PassengerId, \n              'Survived':y_preds})\nsubmission.to_csv('submission.csv', index=False)\npd.read_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}